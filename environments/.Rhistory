index=index+1
list_of_models <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
test_accuracy[[index]] <- pctCorrectOfPredictPair(list(list_of_models),test.set)
cues_selected[[index]] <- models[k,]
}
}
}
test.res[[ind]] <- as.vector(unlist(test_accuracy))
cues.selected[[ind]] <- as.vector(unlist(cues_selected))
#results <- rbind(results,pctCorr)
#final <- colMeans(results)
#test.res[ind,1:7] <- as.vector(final)
#test.res[ind,9:10] <- c(length(subsetcols),length(cols_to_fit))
}
#test.res[,8] <- tset
data.results[[1]] <- list(unlist(test.res),cues.selected)
all[[reps]] <- data.results
}
i=2
keep <- c(1,2,3,4,6,8,9,12,15,18,19,20,21,22,23,24,27,28,30,31,32,33,34,35,36,37,38)
datasets <- datasets[keep]
d=datasets[i]
all <- list()
for(reps in 1:1){
data.results <- list()
data <- read.csv(d,header=F)
criterion_col <- 1
cols_to_fit <- 2:ncol(data)
##calculate all cue combinations for a given dataset
n_cues <- length(cols_to_fit)
cue_comb <- list()
fulllength <- 0
for(f in 1:n_cues){
cue_comb[[f]] <- t(combn(n_cues,f))
fulllength = fulllength + nrow(cue_comb[[f]])
}
total <- list()
#determine size of holdout set
if(nrow(data)>=20){holdout <- 10} else {holdout <- nrow(data)-10} #round(nrow(data)*0.2)
holdoutItems <- sample(1:nrow(data),holdout)
#determine training items
trainItems <- setdiff(1:nrow(data),holdoutItems)
trainVector <-   round(length(trainItems) * seq(0.1,0.9,0.1))
trainVector[trainVector<=1] <- 2
tset <- trainVector
#test.res <- matrix(NA,ncol=fulllength,nrow=length(tset))
test.res <- list()
cues.selected <- list()
ind = 0
for (t in tset){
results <- vector()
ind = ind+1
t1 <- sample(trainItems,t)
train.set <- data[t1,]
test.set <- data[holdoutItems,]
#calculate the fitting accuracy of each model
model_accuracy <- list()
counter=0
for(y in 1:n_cues){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
list_of_models[[k]] <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
}
model_accuracy[[y]] <- pctCorrectOfPredictPair(list_of_models,train.set)
}
fitting.accuracy <- unlist(model_accuracy)
#randomly sample 1 of the best combinations
select <- sample(which(fitting.accuracy==max(fitting.accuracy)),1)
#evaluate all best combinations
# select <- as.vector(which(fitting.accuracy==max(fitting.accuracy)))
test_accuracy <- list()
cues_selected <- list()
counter=0
index=0
for(y in 1:n_cues){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
counter=counter+1
if(any(select==counter)){
index=index+1
list_of_models <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
test_accuracy[[index]] <- pctCorrectOfPredictPair(list(list_of_models),test.set)
cues_selected[[index]] <- models[k,]
}
}
}
test.res[[ind]] <- as.vector(unlist(test_accuracy))
cues.selected[[ind]] <- as.vector(unlist(cues_selected))
#results <- rbind(results,pctCorr)
#final <- colMeans(results)
#test.res[ind,1:7] <- as.vector(final)
#test.res[ind,9:10] <- c(length(subsetcols),length(cols_to_fit))
}
#test.res[,8] <- tset
data.results[[1]] <- list(unlist(test.res),cues.selected)
all[[reps]] <- data.results
}
all
ls()
load("~/Desktop/COLLECTIVE_SEARCH/store20.Rdata")
ls()
ncol(store)
2^20
store[1,]
head(store[1,])
rm(list=ls())
setwd("~/Dropbox/TALLY_K/DATA")
library(heuristica)
datasets <- list.files(pattern="csv")
# load("~/Desktop/names.Rdata")
n.datasets <- length(datasets)
keep <- c(1,2,3,4,6,8,9,12,15,18,19,20,21,22,23,24,27,28,30,31,32,33,34,35,36,37,38)
setdiff(1:39,keep)
datasets <- datasets[setdiff(1:39,keep)]
datasets
load("~/Desktop/names.Rdata")
load("~/Desktop/names.Rdata")
keep <- c(1,2,3,4,6,8,9,12,15,18,19,20,21,22,23,24,27,28,30,31,32,33,34,35,36,37,38)
datasets <- datasets[setdiff(1:39,keep)]
datasets
load("~/Desktop/names.Rdata")
names
datasets <- names[setdiff(1:39,keep)]
datasets
all <- list()
reps=1
i=2
##calculate all cue combinations for a given dataset
n_cues <- length(cols_to_fit)
cue_comb <- list()
fulllength <- 0
for(f in c(i)){
cue_comb[[f]] <- t(combn(n_cues,f))
fulllength = fulllength + nrow(cue_comb[[f]])
}
data <- read.csv(d,header=F)
# print(d)
criterion_col <- 1
cols_to_fit <- 2:ncol(data)
data <- read.csv(d,header=F)
d=datasets[1]
d
data <- read.csv(d,header=F)
# print(d)
criterion_col <- 1
cols_to_fit <- 2:ncol(data)
##calculate all cue combinations for a given dataset
n_cues <- length(cols_to_fit)
cue_comb <- list()
fulllength <- 0
for(f in c(i)){
cue_comb[[f]] <- t(combn(n_cues,f))
fulllength = fulllength + nrow(cue_comb[[f]])
}
i
cue_comb
#determine size of holdout set
if(nrow(data)>=20){holdout <- 10} else {holdout <- nrow(data)-10} #round(nrow(data)*0.2)
holdoutItems <- sample(1:nrow(data),holdout)
#determine training items
trainItems <- setdiff(1:nrow(data),holdoutItems)
trainVector <-   round(length(trainItems) * seq(0.1,0.9,0.1))
trainVector[trainVector<=1] <- 2
tset <- trainVector
#test.res <- matrix(NA,ncol=fulllength,nrow=length(tset))
test.res <- list()
cues.selected <- list()
ind = 0
t=tset[1]
results <- vector()
ind = ind+1
t1 <- sample(trainItems,t)
train.set <- data[t1,]
test.set <- data[holdoutItems,]
#calculate the fitting accuracy of each model
model_accuracy <- list()
counter=0
#calculate the fitting accuracy of each model
model_accuracy <- list()
counter=0
for(y in c(i)){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
list_of_models[[k]] <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
}
model_accuracy[[y]] <- pctCorrectOfPredictPair(list_of_models,train.set)
}
fitting.accuracy <- unlist(model_accuracy)
test_accuracy <- list()
cues_selected <- list()
counter=0
index=0
for(y in c(i)){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
counter=counter+1
if(any(select==counter)){
index=index+1
list_of_models <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
test_accuracy[[index]] <- pctCorrectOfPredictPair(list(list_of_models),test.set)
cues_selected[[index]] <- models[k,]
}
}
}
select <- sample(which(fitting.accuracy==max(fitting.accuracy)),1)
#evaluate all best combinations
# select <- as.vector(which(fitting.accuracy==max(fitting.accuracy)))
test_accuracy <- list()
cues_selected <- list()
counter=0
index=0
for(y in c(i)){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
counter=counter+1
if(any(select==counter)){
index=index+1
list_of_models <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
test_accuracy[[index]] <- pctCorrectOfPredictPair(list(list_of_models),test.set)
cues_selected[[index]] <- models[k,]
}
}
}
test.res[[ind]] <- as.vector(unlist(test_accuracy))
cues.selected[[ind]] <- as.vector(unlist(cues_selected))
#results <- rbind(results,pctCorr)
#final <- colMeans(results)
#test.res[ind,1:7] <- as.vector(final)
#test.res[ind,9:10] <- c(length(subsetcols),length(cols_to_fit))
}
#test.res[,8] <- tset
test_accuracy <- list()
cues_selected <- list()
counter=0
index=0
for(y in c(i)){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
counter=counter+1
if(any(select==counter)){
index=index+1
list_of_models <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
test_accuracy[[index]] <- pctCorrectOfPredictPair(list(list_of_models),test.set)
cues_selected[[index]] <- models[k,]
}
}
}
test.res[[ind]] <- as.vector(unlist(test_accuracy))
cues.selected[[ind]] <- as.vector(unlist(cues_selected))
d
data.results[[1]] <- list(unlist(test.res),cues.selected)
data.results <- list()
data.results[[1]] <- list(unlist(test.res),cues.selected)
data.results[[1]]
#test.res <- matrix(NA,ncol=fulllength,nrow=length(tset))
test.res <- list()
cues.selected <- list()
ind = 0
for (t in tset){
results <- vector()
ind = ind+1
t1 <- sample(trainItems,t)
train.set <- data[t1,]
test.set <- data[holdoutItems,]
#calculate the fitting accuracy of each model
model_accuracy <- list()
counter=0
for(y in c(i)){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
list_of_models[[k]] <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
}
model_accuracy[[y]] <- pctCorrectOfPredictPair(list_of_models,train.set)
}
fitting.accuracy <- unlist(model_accuracy)
#randomly sample 1 of the best combinations
select <- sample(which(fitting.accuracy==max(fitting.accuracy)),1)
#evaluate all best combinations
# select <- as.vector(which(fitting.accuracy==max(fitting.accuracy)))
test_accuracy <- list()
cues_selected <- list()
counter=0
index=0
for(y in c(i)){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
counter=counter+1
if(any(select==counter)){
index=index+1
list_of_models <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
test_accuracy[[index]] <- pctCorrectOfPredictPair(list(list_of_models),test.set)
cues_selected[[index]] <- models[k,]
}
}
}
test.res[[ind]] <- as.vector(unlist(test_accuracy))
cues.selected[[ind]] <- as.vector(unlist(cues_selected))
#results <- rbind(results,pctCorr)
#final <- colMeans(results)
#test.res[ind,1:7] <- as.vector(final)
#test.res[ind,9:10] <- c(length(subsetcols),length(cols_to_fit))
}
t
tset
#test.res <- matrix(NA,ncol=fulllength,nrow=length(tset))
test.res <- list()
cues.selected <- list()
ind = 0
for (t in tset){
results <- vector()
ind = ind+1
t1 <- sample(trainItems,t)
train.set <- data[t1,]
test.set <- data[holdoutItems,]
#calculate the fitting accuracy of each model
model_accuracy <- list()
counter=0
for(y in c(i)){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
list_of_models[[k]] <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
}
model_accuracy[[y]] <- pctCorrectOfPredictPair(list_of_models,train.set)
}
fitting.accuracy <- unlist(model_accuracy)
#randomly sample 1 of the best combinations
select <- sample(which(fitting.accuracy==max(fitting.accuracy)),1)
#evaluate all best combinations
# select <- as.vector(which(fitting.accuracy==max(fitting.accuracy)))
test_accuracy <- list()
cues_selected <- list()
counter=0
index=0
for(y in c(i)){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
counter=counter+1
if(any(select==counter)){
index=index+1
list_of_models <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
test_accuracy[[index]] <- pctCorrectOfPredictPair(list(list_of_models),test.set)
cues_selected[[index]] <- models[k,]
}
}
}
test.res[[ind]] <- as.vector(unlist(test_accuracy))
cues.selected[[ind]] <- as.vector(unlist(cues_selected))
#results <- rbind(results,pctCorr)
#final <- colMeans(results)
#test.res[ind,1:7] <- as.vector(final)
#test.res[ind,9:10] <- c(length(subsetcols),length(cols_to_fit))
}
#test.res[,8] <- tset
data.results[[1]] <- list(unlist(test.res),cues.selected)
list(unlist(test.res),max(fitting.accuracy))
datasets
for(i in dataets) data<-read.csv(d,header=F); print(length(2:ncol(data)))
for(i in datasets) data<-read.csv(d,header=F);print(d); print(length(2:ncol(data)))
datasets
for(d in datasets) data<-read.csv(d,header=F);print(d); print(length(2:ncol(data)))
for(d in datasets){ data<-read.csv(d,header=F);print(d); print(length(2:ncol(data)))}
rm(list=ls())
setwd("~/Dropbox/TALLY_K/DATA")
library(heuristica)
datasets <- list.files(pattern="csv")
n.datasets <- length(datasets)
i <- as.integer( commandArgs(TRUE)[1])
data.results <- list()
for (d in datasets){
data <- read.csv(d,header=F)
criterion_col <- 1
cols_to_fit <- 2:ncol(data)
##calculate all cue combinations for a given dataset
n_cues <- length(cols_to_fit)
cue_comb <- list()
fulllength <- 0
for(f in 1:n_cues){
cue_comb[[f]] <- t(combn(n_cues,f))
fulllength = fulllength + nrow(cue_comb[[f]])
}
total <- list()
#determine size of holdout set
if(nrow(data)>=20){holdout <- 10} else {holdout <- nrow(data)-10} #round(nrow(data)*0.2)
holdoutItems <- sample(1:nrow(data),holdout)
#determine training items
trainItems <- setdiff(1:nrow(data),holdoutItems)
trainVector <-   round(length(trainItems) * seq(0.1,0.9,0.1))
trainVector[trainVector<=1] <- 2
tset <- trainVector
#test.res <- matrix(NA,ncol=fulllength,nrow=length(tset))
test.res <- list()
cues.selected <- list()
ind = 0
for (t in tset){
results <- vector()
ind = ind+1
t1 <- sample(trainItems,t)
train.set <- data[t1,]
test.set <- data[holdoutItems,]
#calculate the fitting accuracy of each model
model_accuracy <- list()
counter=0
for(y in 1:n_cues){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
list_of_models[[k]] <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
}
model_accuracy[[y]] <- pctCorrectOfPredictPair(list_of_models,train.set)
}
fitting.accuracy <- unlist(model_accuracy)
#randomly sample 1 of the best combinations
select <- sample(which(fitting.accuracy==max(fitting.accuracy)),1)
#evaluate all best combinations
# select <- as.vector(which(fitting.accuracy==max(fitting.accuracy)))
test_accuracy <- list()
cues_selected <- list()
counter=0
index=0
for(y in 1:n_cues){
models <- cue_comb[[y]] + 1
list_of_models <- list()
for(k in 1:nrow(models)) {
counter=counter+1
if(any(select==counter)){
index=index+1
list_of_models <- logRegModel(train.set,criterion_col,cols_to_fit=models[k,])
test_accuracy[[index]] <- pctCorrectOfPredictPair(list(list_of_models),test.set)
cues_selected[[index]] <- models[k,]
}
}
}
test.res[[ind]] <- as.vector(unlist(test_accuracy))
cues.selected[[ind]] <- as.vector(unlist(cues_selected))
#results <- rbind(results,pctCorr)
#final <- colMeans(results)
#test.res[ind,1:7] <- as.vector(final)
#test.res[ind,9:10] <- c(length(subsetcols),length(cols_to_fit))
}
#test.res[,8] <- tset
data.results[[d]] <- list(unlist(test.res),cues.selected)
}
MasonWattsOld<-function(L){
R <- 3 * (L/100) #variance term
rho <- 0.7
#1. create function matrix as a unimodal bivariate Gaussian with the mean randomly chosen, with variance R
#generate two random means
X <- dnorm(seq(1,L), mean = runif(1,1,L), sd=sqrt(R))
Y <- dnorm(seq(1,L), mean = runif(1,1,L), sd=sqrt(R))
fitnessMatrix <- X %*% t(Y)
#scale to between 0 and 1 (Not sure if this is what they do)
fitnessMatrix <- fitnessMatrix * (1/max(fitnessMatrix))
#2. compute psuedorandom Perlin noise
#2a loop through octaves and randomly draw values
for (omega in 3:7){
octave <- 2^omega  #scale octave to account for grids larger than original 100x100
#create a smaller matrix, containing only randomly assigned payoffs corresponding to the cells affected by the octave
octaveMatrix <- matrix(runif(octave^2),ncol=octave, nrow=octave)
#center octave sequence on median of grid
octaveSeq <- seq(1,L, length.out=octave)
#2b. smooth values of all cell values using bicubic interpolation
octaveMatrix <- bicubic.grid(octaveSeq, octaveSeq, octaveMatrix, c(1,L), c(1,L),1,1)
#2c. scale matrix by the persistence paramter
octaveMatrix <- octaveMatrix$z * rho^omega
#3. sum together
fitnessMatrix <- fitnessMatrix + octaveMatrix
}
#3 continued... scale fitnessMatrix to between 1 and 100
fitnessMatrix <- fitnessMatrix * (1/max(fitnessMatrix))
return(fitnessMatrix)
#3D plotting example
#https://cran.r-project.org/web/packages/plot3D/vignettes/volcano.pdf
#persp3D(z = test, clab = "m")
}
source("functions.R")
MasonandWattsEnv <- list()
for(i in 1:100){
MasonandWattsEnv[[i]] <-  MasonWatts(1001)
}
setwd("~/GitHub/collective_search/environments/")
source("functions.R")
MasonandWattsEnv <- list()
for(i in 1:100){
MasonandWattsEnv[[i]] <-  MasonWatts(1001)
}
setwd("~/GitHub/collective_search/environments/")
source("functions.R")
MasonWattsEnv <- list()
for(i in 1:100){
MasonWattsEnv[[i]] <-  MasonWatts(1001)
}
setwd("~/GitHub/collective_search/environments/")
source("functions.R")
MasonWattsEnv <- list()
for(i in 1:100){
MasonWattsEnv[[i]] <-  MasonWatts(1001)
}
save(MasonWattsEnv,file="MasonWattsEnv.Rdata")
write.matrix(MasonWattsEnv,file="~/Desktop/MasonWattsEnv")
library(MASS)
write.matrix(MasonWattsEnv,file="~/Desktop/MasonWattsEnv")
MasonWattsEnv[[1]]
